# Масштабирование и оптимизация forex-news-bot (370 → 1000 пользователей)

**Дата:** 12 февраля 2026  
**Цель:** Стабильная работа при 370 пользователях и подготовка к 1000.

---

## 1. Текущее состояние

### 1.1 Нагрузка и метрики (на 370 пользователях)

- **Heap usage:** ~95% (~60 MiB) — процесс близок к OOM.
- **Рестарты:** 16 за 15 минут — нестабильность, вероятные OOM или необработанные ошибки.
- **Event loop latency:** ~0.90 ms — блокировок нет, узкое место по памяти.
- **Логи:** Массовые записи `[MyfxbookService] Filtered out event...` и `[DataQualityService] Filtering...`.

### 1.2 Архитектура нагрузки

- **Scheduler:** каждые 3 минуты запускается проверка по **всем** пользователям.
- **Параллелизм:** `Promise.allSettled(users.map(...))` — до 370 одновременных вызовов `aggregateCoreEvents()`.
- **На каждый вызов:** получение событий (ForexFactory/Myfxbook с кешем по URL), фильтрация по TZ пользователя, дедупликация, DataQuality, отправка напоминаний/результатов.
- **Итог:** пиковая память и объём логов растут с числом пользователей.

### 1.3 Сервер (VPS)

- **Модель:** Cloud VPS 20 SSD
- **Ресурсы:** 6 CPU, 12 GB RAM, 200 GB SSD, 300 Mbit/s
- **Вывод:** ресурсов достаточно; узкое место — настройки процесса и код (heap, параллелизм, логи).

---

## 2. Нужна ли смена подписки на сервер?

**Сначала — нет.** Приоритет: стабилизация на текущем железе.

- Ввести лимит heap, снизить логи, ограничить параллелизм (батчи).
- Наблюдать 1–2 дня при 370 пользователях.
- Если стабильно — тестировать рост до 1000.
- **Апгрейд VPS** рассматривать только если после оптимизаций при 370 остаётся нестабильность или при 1000 снова упираетесь в память/CPU.

---

## 3. План оптимизации

### Фаза 1 — Срочные меры (без смены тарифа)

| № | Действие | Где | Ожидаемый эффект |
|---|----------|-----|-------------------|
| 1.1 | Увеличить лимит heap Node.js | PM2 / скрипт запуска | Меньше OOM и рестартов |
| 1.2 | Снизить объём логов | MyfxbookService, DataQualityService | Меньше I/O и нагрузки |
| 1.3 | Обрабатывать пользователей батчами (30–50) | SchedulerService | Снижение пиковой памяти и CPU |
| 1.4 | Ограничить длину очереди сообщений | MessageQueue | Нет неограниченного роста при будущем использовании |
| 1.5 | Очистка/TTL для userStates (опционально) | bot.ts | Ограничение роста памяти от состояний |

**Детали:**

- **1.1** — `NODE_OPTIONS=--max-old-space-size=2048` (или 3072). В PM2: `node_args: '--max-old-space-size=2048'`.
- **1.2** — Убрать или перевести в debug лог каждого «Filtered out event» в MyfxbookService; в DataQuality оставить один сводный лог на батч.
- **1.3** — Разбить `users` на чанки по 30–50, обрабатывать `Promise.allSettled(chunk.map(...))` по чанкам последовательно (с паузой 100–200 ms между чанками при необходимости).
- **1.4** — Ввести максимальную длину очереди (например, 2000); при переполнении не добавлять и логировать.
- **1.5** — Либо TTL ≥ 30 мин по последней активности, либо не внедрять в первой фазе.

### Фаза 2 — Стабилизация

| № | Действие | Где | Ожидаемый эффект |
|---|----------|-----|-------------------|
| 2.1 | Общий кеш событий по дню + фильтр по TZ (рефакторинг) | eventAggregation / сервисы | Меньше дублирования и логов |
| 2.2 | Ограничение размера кеша AnalysisService (max entries / LRU) | AnalysisService | Стабильная память в длительном режиме |
| 2.3 | PM2 ecosystem | ecosystem.config.js | Предсказуемый запуск и рестарты |

**Детали:**

- **2.1** — Один общий слой «сырых» событий по URL/дню; фильтрация по TZ пользователя в одном месте или по группам TZ. Требует тестов по границам суток и разным TZ.
- **2.2** — Макс. число записей в кеше (500–1000), вытеснение по возрасту/expires.
- **2.3** — `node_args`, `max_restarts`, `min_uptime`, при необходимости `exp_backoff_restart_delay`. Не занижать `max_restarts` до устранения причин падений.

### Фаза 3 — Масштабирование до 1000

- Мониторинг 1–2 дня после Фазы 1–2 при 370 пользователях.
- Постепенное увеличение нагрузки или тест на 1000.
- При повторном упирании в ресурсы — рассмотреть апгрейд VPS или разделение ролей (отдельный воркер для парсинга/тяжёлой логики).

---

## 4. Оценка рисков по изменениям

### 4.1 Увеличение heap

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Конфликт NODE_OPTIONS / способа запуска | Низкий | Проверить фактический запуск и логи/метрики |
| Слишком большой heap при нескольких процессах | Средний | Один процесс с 2–3 GB на 12 GB RAM — ок |

### 4.2 Снижение логирования

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Потеря диагностики при багах фильтрации | Средний | Сводные логи или вывод только при LOG_LEVEL=debug |

### 4.3 Батчи в SchedulerService

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Часть пользователей не обрабатывается (ошибка в разбиении) | Высокий | Корректный slice по фиксированному batchSize, проверка счётчиков |
| Небольшая задержка доставки для последних батчей | Средний | Приемлемо для напоминаний «за 15 мин» |

### 4.4 Ограничение MessageQueue

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Потеря сообщений при будущем использовании очереди | Высокий (если очередь начнут использовать) | Лимит 2000+, логирование переполнения; сейчас очередь не используется рассылками |

### 4.5 TTL для userStates

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Сброс состояния во время сценария (вопрос/таймзона) | Высокий | TTL только по «забытым» (≥30 мин с последней активности) или не внедрять в первой фазе |

### 4.6 Общий кеш по TZ (рефакторинг)

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Неверный «сегодня/завтра» для части TZ (граница суток) | Высокий | Отдельная задача с тестами по разным TZ и времени |
| Учёт источников (ForexFactory/Myfxbook/Both) | Высокий | Кеш по (источник + день), тесты |

### 4.7 LRU в AnalysisService

| Риск | Уровень | Митигация |
|------|--------|-----------|
| Вытеснение часто используемых ключей | Средний | Размер 500–1000, мониторинг доли кеш-хитов |

### 4.8 PM2 ecosystem

| Риск | Уровень | Митигация |
|------|--------|-----------|
| PM2 перестаёт рестартить при постоянных падениях (max_restarts) | Высокий | Не занижать max_restarts до стабилизации |
| Несовпадение способа запуска (ts-node vs node) | Средний | Явно прописать в ecosystem и проверить после деплоя |

---

## 5. Риски со стороны пользователя (при обновлении)

Что может заметить пользователь бота во время и после деплоя оптимизаций: задержки, сбои, баги.

### 5.1 Во время деплоя (перезапуск процесса)

| Что может произойти | Как проявляется для пользователя | Длительность |
|---------------------|-----------------------------------|--------------|
| Простой бота | Команды (/start, /daily, /settings) не отвечают или «зависают» | 10–60 сек при рестарте |
| Обрыв диалога | Пользователь в середине настройки (часовой пояс, вопрос к AI) — ответ бота не приходит | До следующей попытки пользователя |
| Таймаут Telegram | «Сообщение не доставлено» или повторная отправка команды | Зависит от клиента |

**Рекомендация:** по возможности деплоить в период минимальной активности (ночь по основной аудитории).

### 5.2 После деплоя — задержки

| Причина | Проявление | Оценка |
|---------|------------|--------|
| Батчи в Scheduler | Пользователи из последних батчей получают напоминание «за 15 мин» с задержкой до 1–2 мин (например, в 14 мин до события) | Нормально для уведомлений |
| Первый запрос после рестарта | /daily или календарь дольше грузятся (холодный кеш, парсинг) | 30–60 сек один раз |
| Очередь сообщений (если ограничили и она переполнена) | Часть ответов не доходит (при текущем коде рассылки идут мимо очереди — риска нет) | Только если очередь начнут использовать |

### 5.3 После деплоя — возможные баги и вылеты

| Риск | Как пользователь это видит | Вероятность |
|------|-----------------------------|-------------|
| Рестарты из‑за OOM (до увеличения heap) | Бот перестаёт отвечать на 10–30 сек, потом снова работает; уведомления за окно рестарта могут не прийти | Высокая до Фазы 1 |
| Ошибка в батчах (часть пользователей не обрабатывается) | Отдельные пользователи не получают дайджест в 08:00 или напоминания за 15 мин | Низкая при корректной реализации |
| Сброс userStates по TTL (если внедрить) | Пользователь ввёл часовой пояс или вопрос — бот обработал как обычное сообщение, настройка не применилась | Средняя при коротком TTL |
| Неверный «сегодня/завтра» при рефакторинге кеша по TZ | В /daily или /tomorrow события за другой день или пустой список | Низкая при тестах по TZ |
| PM2 перестал рестартить (max_restarts) | Бот «завис» навсегда до ручного перезапуска | Низкая при осторожных настройках |

### 5.4 Итог для пользователя

- **Во время обновления:** возможен короткий простой (десятки секунд), обрыв текущего диалога.
- **После обновления:** в норме — стабильная работа, реже «зависания» и пропуски из‑за рестартов. Редко — задержка напоминаний на 1–2 мин у части пользователей (батчи) или единичные баги при ошибках в коде (батчи/TTL/кеш).
- **Коммуникация:** при плановом обновлении можно кратко предупредить в канале/чате: «Краткое техобслуживание сегодня в [время], бот может не отвечать 1–2 минуты».

---

## 6. Рекомендуемый порядок внедрения

1. **Минимальный риск:** увеличение heap, снижение логов (сводки вместо каждой строки).
2. **Контролируемый риск:** батчи в SchedulerService + проверка логики и выборочная проверка доставки; PM2 ecosystem с осторожными max_restarts.
3. **Отложить или с тестами:** ограничение MessageQueue (низкий риск при текущем коде); TTL userStates — только с длинным TTL или не в первой фазе; общий кеш по TZ и LRU AnalysisService — отдельные задачи с тестами и мониторингом.

---

## 7. Чек-лист перед деплоем

- [x] Резервная копия БД и конфигурации — `bash scripts/pre-deploy-backup.sh`
- [x] Проверка текущего способа запуска (ts-node / node, переменные окружения) — см. `PRE_DEPLOY_CHECKLIST.md`
- [x] Зафиксировать текущие метрики PM2 (heap, restarts, uptime) — `bash scripts/pre-deploy-metrics.sh`
- [x] Логирование ошибок (uncaughtException, unhandledRejection, bot.catch) — реализовано в `bot.ts`

---

## 8. Чек-лист после деплоя (Фаза 1)

- [ ] Процесс стартует с новым heap (проверка в PM2 или логах)
- [ ] Рестарты за первый час/два снизились или отсутствуют
- [ ] Heap usage стабильно ниже 80–85%
- [ ] Напоминания и рассылки приходят (выборочная проверка пользователей из разных «батчей»)
- [ ] В логах нет массового «Filtered out event» при обычном уровне детализации

---

## 9. Связанные документы

- `SECURITY.md` — безопасность и переменные окружения.
- `DATA_QUALITY_AUDIT_REPORT.md` — качество данных и фильтрация.
